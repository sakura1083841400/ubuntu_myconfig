{
  "reference": "https://huggingface.co/jartine/WizardCoder-Python-34B-V1.0-llamafile",
  "wizardcoder-python-34b-v1.0.Q2_K": {
    "download": "https://huggingface.co/jartine/wizardcoder-python-34b-v1.0-llamafile/resolve/main/wizardcoder-python-34b-v1.0.Q2_K.llamafile",
    "bits": 2,
    "quant-method": "Q2_K",
    "size": "14.21 GB",
    "max-ram-required": "16.71 GB",
    "usecase": "smallest, significant quality loss - not recommended for most purposes"
  },
  "wizardcoder-python-34b-v1.0.Q3_K_S": {
    "download": "https://huggingface.co/jartine/wizardcoder-python-34b-v1.0-llamafile/resolve/main/wizardcoder-python-34b-v1.0.Q3_K_S.llamafile",
    "bits": 3,
    "quant-method": "Q3_K_S",
    "size": "14.61 GB",
    "max-ram-required": "17.11 GB",
    "usecase": "very small, high quality loss"
  },
  "wizardcoder-python-34b-v1.0.Q3_K_M": {
    "download": "https://huggingface.co/jartine/wizardcoder-python-34b-v1.0-llamafile/resolve/main/wizardcoder-python-34b-v1.0.Q3_K_M.llamafile",
    "bits": 3,
    "quant-method": "Q3_K_M",
    "size": "16.28 GB",
    "max-ram-required": "18.78 GB",
    "usecase": "very small, high quality loss"
  },
  "wizardcoder-python-34b-v1.0.Q3_K_L": {
    "download": "https://huggingface.co/jartine/wizardcoder-python-34b-v1.0-llamafile/resolve/main/wizardcoder-python-34b-v1.0.Q3_K_L.llamafile",
    "bits": 3,
    "quant-method": "Q3_K_L",
    "size": "17.77 GB",
    "max-ram-required": "20.27 GB",
    "usecase": "small, substantial quality loss"
  },
  "wizardcoder-python-34b-v1.0.Q4_0": {
    "download": "https://huggingface.co/jartine/wizardcoder-python-34b-v1.0-llamafile/resolve/main/wizardcoder-python-34b-v1.0.Q4_0.llamafile",
    "bits": 4,
    "quant-method": "Q4_0",
    "size": "19.05 GB",
    "max-ram-required": "21.55 GB",
    "usecase": "legacy; small, very high quality loss - prefer using Q3_K_M"
  },
  "wizardcoder-python-34b-v1.0.Q4_K_S": {
    "download": "https://huggingface.co/jartine/wizardcoder-python-34b-v1.0-llamafile/resolve/main/wizardcoder-python-34b-v1.0.Q4_K_S.llamafile",
    "bits": 4,
    "quant-method": "Q4_K_S",
    "size": "19.15 GB",
    "max-ram-required": "21.65 GB",
    "usecase": "small, greater quality loss"
  },
  "wizardcoder-python-34b-v1.0.Q4_K_M": {
    "download": "https://huggingface.co/jartine/wizardcoder-python-34b-v1.0-llamafile/resolve/main/wizardcoder-python-34b-v1.0.Q4_K_M.llamafile",
    "bits": 4,
    "quant-method": "Q4_K_M",
    "size": "20.22 GB",
    "max-ram-required": "22.72 GB",
    "usecase": "medium, balanced quality - recommended"
  },
  "wizardcoder-python-34b-v1.0.Q5_0": {
    "download": "https://huggingface.co/jartine/wizardcoder-python-34b-v1.0-llamafile/resolve/main/wizardcoder-python-34b-v1.0.Q5_0.llamafile",
    "bits": 5,
    "quant-method": "Q5_0",
    "size": "23.24 GB",
    "max-ram-required": "25.74 GB",
    "usecase": "legacy; medium, balanced quality - prefer using Q4_K_M"
  },
  "wizardcoder-python-34b-v1.0.Q5_K_S": {
    "download": "https://huggingface.co/jartine/wizardcoder-python-34b-v1.0-llamafile/resolve/main/wizardcoder-python-34b-v1.0.Q5_K_S.llamafile",
    "bits": 5,
    "quant-method": "Q5_K_S",
    "size": "23.24 GB",
    "max-ram-required": "25.74 GB",
    "usecase": "large, low quality loss - recommended"
  },
  "wizardcoder-python-34b-v1.0.Q5_K_M": {
    "download": "https://huggingface.co/jartine/wizardcoder-python-34b-v1.0-llamafile/resolve/main/wizardcoder-python-34b-v1.0.Q5_K_M.llamafile",
    "bits": 5,
    "quant-method": "Q5_K_M",
    "size": "23.84 GB",
    "max-ram-required": "26.34 GB",
    "usecase": "large, very low quality loss - recommended"
  },
  "wizardcoder-python-34b-v1.0.Q6_K": {
    "download": "https://huggingface.co/jartine/wizardcoder-python-34b-v1.0-llamafile/resolve/main/wizardcoder-python-34b-v1.0.Q6_K.llamafile",
    "bits": 6,
    "quant-method": "Q6_K",
    "size": "27.68 GB",
    "max-ram-required": "30.18 GB",
    "usecase": "very large, extremely low quality loss"
  },
  "wizardcoder-python-34b-v1.0.Q8_0": {
    "download": "https://huggingface.co/jartine/wizardcoder-python-34b-v1.0-llamafile/resolve/main/wizardcoder-python-34b-v1.0.Q8_0.llamafile",
    "bits": 8,
    "quant-method": "Q8_0",
    "size": "35.86 GB",
    "max-ram-required": "38.36 GB",
    "usecase": "very large, extremely low quality loss - not recommended"
  }
}
