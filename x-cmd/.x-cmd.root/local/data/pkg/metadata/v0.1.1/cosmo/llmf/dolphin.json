{
  "reference": "https://huggingface.co/jartine/dolphin-2.5-mixtral-8x7b-llamafile",
  "2.5-mixtral": {
    "8x7b": {
      "q2_k": {
        "format": "llamafile",
        "hf": "jartine/dolphin-2.5-mixtral-8x7b-llamafile/resolve/main/dolphin-2.5-mixtral-8x7b.Q2_K.llamafile",
        "bits": 2,
        "quant-method": "Q2_K",
        "size": "15.64 GB",
        "max-ram-required": "18.14 GB",
        "usecase": "smallest, significant quality loss - not recommended for most purposes"
      }
    }
  },
  "dolphin-2.5-mixtral-8x7b.Q2_K": {
    "download": "https://huggingface.co/jartine/dolphin-2.5-mixtral-8x7b-llamafile/resolve/main/dolphin-2.5-mixtral-8x7b.Q2_K.llamafile",
    "bits": 2,
    "quant-method": "Q2_K",
    "size": "15.64 GB",
    "max-ram-required": "18.14 GB",
    "usecase": "smallest, significant quality loss - not recommended for most purposes"
  },
  "dolphin-2.5-mixtral-8x7b.Q3_K_M": {
    "download": "https://huggingface.co/jartine/dolphin-2.5-mixtral-8x7b-llamafile/resolve/main/dolphin-2.5-mixtral-8x7b.Q3_K_M.llamafile",
    "bits": 3,
    "quant-method": "Q3_K_M",
    "size": "20.36 GB",
    "max-ram-required": "22.86 GB",
    "usecase": "very small, high quality loss"
  },
  "dolphin-2.5-mixtral-8x7b.Q4_0": {
    "download": "https://huggingface.co/jartine/dolphin-2.5-mixtral-8x7b-llamafile/resolve/main/dolphin-2.5-mixtral-8x7b.Q4_0.llamafile",
    "bits": 4,
    "quant-method": "Q4_0",
    "size": "26.44 GB",
    "max-ram-required": "28.94 GB",
    "usecase": "legacy; small, very high quality loss - prefer using Q3_K_M"
  },
  "dolphin-2.5-mixtral-8x7b.Q4_K_M": {
    "download": "https://huggingface.co/jartine/dolphin-2.5-mixtral-8x7b-llamafile/resolve/main/dolphin-2.5-mixtral-8x7b.Q4_K_M.llamafile",
    "bits": 4,
    "quant-method": "Q4_K_M",
    "size": "26.44 GB",
    "max-ram-required": "28.94 GB",
    "usecase": "medium, balanced quality - recommended"
  },
  "dolphin-2.5-mixtral-8x7b.Q5_0": {
    "download": "https://huggingface.co/jartine/dolphin-2.5-mixtral-8x7b-llamafile/resolve/main/dolphin-2.5-mixtral-8x7b.Q5_0.llamafile",
    "bits": 5,
    "quant-method": "Q5_0",
    "size": "32.23 GB",
    "max-ram-required": "34.73 GB",
    "usecase": "legacy; medium, balanced quality - prefer using Q4_K_M"
  },
  "dolphin-2.5-mixtral-8x7b.Q5_K_M": {
    "download": "https://huggingface.co/jartine/dolphin-2.5-mixtral-8x7b-llamafile/resolve/main/dolphin-2.5-mixtral-8x7b.Q5_K_M.llamafile",
    "bits": 5,
    "quant-method": "Q5_K_M",
    "size": "32.23 GB",
    "max-ram-required": "34.73 GB",
    "usecase": "large, very low quality loss - recommended"
  },
  "dolphin-2.5-mixtral-8x7b.Q6_K": {
    "download": "https://huggingface.co/jartine/dolphin-2.5-mixtral-8x7b-llamafile/resolve/main/dolphin-2.5-mixtral-8x7b.Q6_K.llamafile",
    "bits": 6,
    "quant-method": "Q6_K",
    "size": "38.38 GB",
    "max-ram-required": "40.88 GB",
    "usecase": "very large, extremely low quality loss"
  },
  "dolphin-2.5-mixtral-8x7b.Q8_0": {
    "download": "https://huggingface.co/jartine/dolphin-2.5-mixtral-8x7b-llamafile/resolve/main/dolphin-2.5-mixtral-8x7b.Q8_0.llamafile",
    "bits": 8,
    "quant-method": "Q8_0",
    "size": "49.62 GB",
    "max-ram-required": "52.12 GB",
    "usecase": "very large, extremely low quality loss - not recommended"
  }
}
