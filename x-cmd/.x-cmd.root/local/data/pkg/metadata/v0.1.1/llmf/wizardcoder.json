{
  "python-13b-v1.0": {
    "q2_k": {
      "format": "gguf",
      "hf": "TheBloke/WizardCoder-Python-13B-V1.0-GGUF/resolve/main/wizardcoder-python-13b-v1.0.Q2_K.gguf",
      "bits": 2,
      "quant-method": "Q2_K",
      "size": "5.43 GB",
      "max-ram-required": "7.93 GB",
      "usecase": "smallest, significant quality loss - not recommended for most purposes"
    },
    "q3_k_s": {
      "format": "gguf",
      "hf": "TheBloke/WizardCoder-Python-13B-V1.0-GGUF/resolve/main/wizardcoder-python-13b-v1.0.Q3_K_S.gguf",
      "bits": 3,
      "quant-method": "Q3_K_S",
      "size": "5.66 GB",
      "max-ram-required": "8.16 GB",
      "usecase": "very small, high quality loss"
    },
    "q3_k_m": {
      "format": "gguf",
      "hf": "TheBloke/WizardCoder-Python-13B-V1.0-GGUF/resolve/main/wizardcoder-python-13b-v1.0.Q3_K_M.gguf",
      "bits": 3,
      "quant-method": "Q3_K_M",
      "size": "6.34 GB",
      "max-ram-required": "8.84 GB",
      "usecase": "very small, high quality loss"
    },
    "q3_k_l": {
      "format": "gguf",
      "hf": "TheBloke/WizardCoder-Python-13B-V1.0-GGUF/resolve/main/wizardcoder-python-13b-v1.0.Q3_K_L.gguf",
      "bits": 3,
      "quant-method": "Q3_K_L",
      "size": "6.93 GB",
      "max-ram-required": "9.43 GB",
      "usecase": "small, substantial quality loss"
    },
    "q4_0": {
      "format": "gguf",
      "hf": "TheBloke/WizardCoder-Python-13B-V1.0-GGUF/resolve/main/wizardcoder-python-13b-v1.0.Q4_0.gguf",
      "bits": 4,
      "quant-method": "Q4_0",
      "size": "7.37 GB",
      "max-ram-required": "9.87 GB",
      "usecase": "legacy; small, very high quality loss - prefer using Q3_K_M"
    },
    "q4_k_s": {
      "format": "gguf",
      "hf": "TheBloke/WizardCoder-Python-13B-V1.0-GGUF/resolve/main/wizardcoder-python-13b-v1.0.Q4_K_S.gguf",
      "bits": 4,
      "quant-method": "Q4_K_S",
      "size": "7.41 GB",
      "max-ram-required": "9.91 GB",
      "usecase": "small, greater quality loss"
    },
    "q4_k_m": {
      "format": "gguf",
      "hf": "TheBloke/WizardCoder-Python-13B-V1.0-GGUF/resolve/main/wizardcoder-python-13b-v1.0.Q4_K_M.gguf",
      "bits": 4,
      "quant-method": "Q4_K_M",
      "size": "7.87 GB",
      "max-ram-required": "10.37 GB",
      "usecase": "medium, balanced quality - recommended"
    },
    "q5_0": {
      "format": "gguf",
      "hf": "TheBloke/WizardCoder-Python-13B-V1.0-GGUF/resolve/main/wizardcoder-python-13b-v1.0.Q5_0.gguf",
      "bits": 5,
      "quant-method": "Q5_0",
      "size": "8.97 GB",
      "max-ram-required": "11.47 GB",
      "usecase": "legacy; medium, balanced quality - prefer using Q4_K_M"
    },
    "q5_k_s": {
      "format": "gguf",
      "hf": "TheBloke/WizardCoder-Python-13B-V1.0-GGUF/resolve/main/wizardcoder-python-13b-v1.0.Q5_K_S.gguf",
      "bits": 5,
      "quant-method": "Q5_K_S",
      "size": "8.97 GB",
      "max-ram-required": "11.47 GB",
      "usecase": "large, low quality loss - recommended"
    },
    "q5_k_m": {
      "format": "gguf",
      "hf": "TheBloke/WizardCoder-Python-13B-V1.0-GGUF/resolve/main/wizardcoder-python-13b-v1.0.Q5_K_M.gguf",
      "bits": 5,
      "quant-method": "Q5_K_M",
      "size": "9.23 GB",
      "max-ram-required": "11.73 GB",
      "usecase": "large, very low quality loss - recommended"
    },
    "q6_k": {
      "format": "gguf",
      "hf": "TheBloke/WizardCoder-Python-13B-V1.0-GGUF/resolve/main/wizardcoder-python-13b-v1.0.Q6_K.gguf",
      "bits": 6,
      "quant-method": "Q6_K",
      "size": "10.68 GB",
      "max-ram-required": "13.18 GB",
      "usecase": "very large, extremely low quality loss"
    },
    "q8_0": {
      "format": "gguf",
      "hf": "TheBloke/WizardCoder-Python-13B-V1.0-GGUF/resolve/main/wizardcoder-python-13b-v1.0.Q8_0.gguf",
      "bits": 8,
      "quant-method": "Q8_0",
      "size": "13.83 GB",
      "max-ram-required": "16.33 GB",
      "usecase": "very large, extremely low quality loss - not recommended"
    }
  },
  "python-34b-v1.0": {
    "q2_k": {
      "format": "gguf",
      "hf": "TheBloke/WizardCoder-Python-34B-V1.0-GGUF/resolve/main/wizardcoder-python-34b-v1.0.Q2_K.gguf",
      "bits": 2,
      "quant-method": "Q2_K",
      "size": "14.21 GB",
      "max-ram-required": "16.71 GB",
      "usecase": "smallest, significant quality loss - not recommended for most purposes"
    },
    "q3_k_s": {
      "format": "gguf",
      "hf": "TheBloke/WizardCoder-Python-34B-V1.0-GGUF/resolve/main/wizardcoder-python-34b-v1.0.Q3_K_S.gguf",
      "bits": 3,
      "quant-method": "Q3_K_S",
      "size": "14.61 GB",
      "max-ram-required": "17.11 GB",
      "usecase": "very small, high quality loss"
    },
    "q3_k_m": {
      "format": "gguf",
      "hf": "TheBloke/WizardCoder-Python-34B-V1.0-GGUF/resolve/main/wizardcoder-python-34b-v1.0.Q3_K_M.gguf",
      "bits": 3,
      "quant-method": "Q3_K_M",
      "size": "16.28 GB",
      "max-ram-required": "18.78 GB",
      "usecase": "very small, high quality loss"
    },
    "q3_k_l": {
      "format": "gguf",
      "hf": "TheBloke/WizardCoder-Python-34B-V1.0-GGUF/resolve/main/wizardcoder-python-34b-v1.0.Q3_K_L.gguf",
      "bits": 3,
      "quant-method": "Q3_K_L",
      "size": "17.77 GB",
      "max-ram-required": "20.27 GB",
      "usecase": "small, substantial quality loss"
    },
    "q4_0": {
      "format": "gguf",
      "hf": "TheBloke/WizardCoder-Python-34B-V1.0-GGUF/resolve/main/wizardcoder-python-34b-v1.0.Q4_0.gguf",
      "bits": 4,
      "quant-method": "Q4_0",
      "size": "19.05 GB",
      "max-ram-required": "21.55 GB",
      "usecase": "legacy; small, very high quality loss - prefer using Q3_K_M"
    },
    "q4_k_s": {
      "format": "gguf",
      "hf": "TheBloke/WizardCoder-Python-34B-V1.0-GGUF/resolve/main/wizardcoder-python-34b-v1.0.Q4_K_S.gguf",
      "bits": 4,
      "quant-method": "Q4_K_S",
      "size": "19.15 GB",
      "max-ram-required": "21.65 GB",
      "usecase": "small, greater quality loss"
    },
    "q4_k_m": {
      "format": "gguf",
      "hf": "TheBloke/WizardCoder-Python-34B-V1.0-GGUF/resolve/main/wizardcoder-python-34b-v1.0.Q4_K_M.gguf",
      "bits": 4,
      "quant-method": "Q4_K_M",
      "size": "20.22 GB",
      "max-ram-required": "22.72 GB",
      "usecase": "medium, balanced quality - recommended"
    },
    "q5_0": {
      "format": "gguf",
      "hf": "TheBloke/WizardCoder-Python-34B-V1.0-GGUF/resolve/main/wizardcoder-python-34b-v1.0.Q5_0.gguf",
      "bits": 5,
      "quant-method": "Q5_0",
      "size": "23.24 GB",
      "max-ram-required": "25.74 GB",
      "usecase": "legacy; medium, balanced quality - prefer using Q4_K_M"
    },
    "q5_k_s": {
      "format": "gguf",
      "hf": "TheBloke/WizardCoder-Python-34B-V1.0-GGUF/resolve/main/wizardcoder-python-34b-v1.0.Q5_K_S.gguf",
      "bits": 5,
      "quant-method": "Q5_K_S",
      "size": "23.24 GB",
      "max-ram-required": "25.74 GB",
      "usecase": "large, low quality loss - recommended"
    },
    "q5_k_m": {
      "format": "gguf",
      "hf": "TheBloke/WizardCoder-Python-34B-V1.0-GGUF/resolve/main/wizardcoder-python-34b-v1.0.Q5_K_M.gguf",
      "bits": 5,
      "quant-method": "Q5_K_M",
      "size": "23.84 GB",
      "max-ram-required": "26.34 GB",
      "usecase": "large, very low quality loss - recommended"
    },
    "q6_k": {
      "format": "gguf",
      "hf": "TheBloke/WizardCoder-Python-34B-V1.0-GGUF/resolve/main/wizardcoder-python-34b-v1.0.Q6_K.gguf",
      "bits": 6,
      "quant-method": "Q6_K",
      "size": "27.68 GB",
      "max-ram-required": "30.18 GB",
      "usecase": "very large, extremely low quality loss"
    },
    "q8_0": {
      "format": "gguf",
      "hf": "TheBloke/WizardCoder-Python-34B-V1.0-GGUF/resolve/main/wizardcoder-python-34b-v1.0.Q8_0.gguf",
      "bits": 8,
      "quant-method": "Q8_0",
      "size": "35.86 GB",
      "max-ram-required": "38.36 GB",
      "usecase": "very large, extremely low quality loss - not recommended"
    }
  }
}
