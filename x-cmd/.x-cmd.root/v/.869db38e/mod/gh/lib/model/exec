# shellcheck shell=dash

___x_cmd_gh_model_chat_exec(){
    local cfg_model=;       local cfg_maxtoken=;    local cfg_seed=;    local cfg_temperature=
    ___x_cmd_gh_cfg --var cfg_model=ai_model cfg_maxtoken=ai_maxtoken cfg_seed=ai_seed cfg_temperature=ai_temperature 2>/dev/null
    cfg_model="${cfg_model:-"$____X_CMD_GH_MODEL_DEFAULT_NAME"}"

    gh:debug --cfg_model "$cfg_model" --cfg_maxtoken "$cfg_maxtoken" --cfg_seed "$cfg_seed" --cfg_temperature "$cfg_temperature" "chat request"

    {
        provider_name=gh \
        ___x_cmd cawk  -E ___X_CMD_CHAT_SESSION_DIR,session,history_num,minion,model,chatid,minion_json_cache,system,type,filelist_attach,temperature   \
                -E cfg_history_num,cfg_session,cfg_minion,cfg_model,cfg_maxtoken,cfg_seed,cfg_temperature \
                -m j/json,j/jiter,j/jcp \
                -f "$___X_CMD_ROOT_MOD/chat/lib/awk/history.awk"        \
                -f "$___X_CMD_ROOT_MOD/chat/lib/awk/util.awk"           \
                -f "$___X_CMD_ROOT_MOD/chat/lib/awk/minion.awk"         \
                -f "$___X_CMD_ROOT_MOD/chat/lib/awk/creq.awk"           \
                -f "$___X_CMD_ROOT_MOD/chat/lib/awk/cres.awk"           \
                -f "$___X_CMD_ROOT_MOD/openai/lib/awk/openai.awk"       \
                -f "$___X_CMD_ROOT_MOD/openai/lib/awk/handle_request.awk" <<A
${question}
${___X_CMD_UNSEENCHAR_001}${___X_CMD_UNSEENCHAR_002}${___X_CMD_UNSEENCHAR_003}:image
${imagelist}
A
    } | ( ___x_cmd_gh_model_chat_request___launch )
}
